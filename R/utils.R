#' Generate a Region Of Interest (ROI) List
#'
#' Generate a ROIList as expected by \code{\link[xcms]{findChromPeaks-centWave}} from a \code{\link{data.frame}} with compounds to target as rows. \emph{length} and \emph{intensity} are set to \code{-1} as centWave does not use these values.
#'
#' @param rawSpec an \code{\link[MSnbase]{OnDiskMSnExp-class}} used to get the scans corresponding to each retention time.
#' @param targetFeatTable a \code{\link{data.frame}} of compounds to target as rows. Columns: \code{cpdID} (int), \code{cpdName} (str), \code{rtMin} (float in seconds), \code{rt} (float in seconds, or \emph{NA}), \code{rtMax} (float in seconds), \code{mzMin} (float), \code{mz} (float or \emph{NA}), \code{mzMax} (float).
#'
#' @return a list of ROIs
#'
#' @examples
#' \dontrun{
#' ## Load data
#' library(faahKO)
#' library(MSnbase)
#' netcdfFilePath <- system.file('cdf/KO/ko15.CDF', package = "faahKO")
#' raw_data       <- MSnbase::readMSData(netcdfFilePath, centroided=TRUE, mode='onDisk')
#'
#' ## targetFeatTable
#' targetFeatTable     <- data.frame(matrix(vector(), 2, 8, dimnames=list(c(), c("cpdID",
#'                          "cpdName", "rtMin", "rt", "rtMax", "mzMin", "mz", "mzMax"))),
#'                          stringsAsFactors=F)
#' targetFeatTable[1,] <- c(1, "Cpd 1", 3310., 3344.888, 3390., 522.194778, 522.2, 522.205222)
#' targetFeatTable[2,] <- c(2, "Cpd 2", 3280., 3385.577, 3440., 496.195038, 496.2, 496.204962)
#' targetFeatTable[,c(1,3:8)] <- sapply(targetFeatTable[,c(1,3:8)], as.numeric)
#'
#' ROIList <- makeROIList(raw_data, targetFeatTable)
#' ROIList[[1]]
#' # $mz
#' # [1] 522.2
#' #
#' # $mzmin
#' # [1] 522.194778
#' #
#' # $mzmax
#' # [1] 522.205222
#' #
#' # $scmin
#' # [1] 518
#' #
#' # $scmax
#' # [1] 569
#' #
#' # $length
#' # [1] -1
#' #
#' # $intensity
#' # [1] -1
#' }
makeROIList        <- function(rawSpec, targetFeatTable) {
  ROIList <- list()
	# single load of scanID/RT from file
	RTtime 	<- MSnbase::rtime(rawSpec)
  for (i in 1:dim(targetFeatTable)[1]) {
    # find the closest scan matching the retention time
    scmin 	<- which.min(abs(targetFeatTable$rtMin[i] - RTtime))[[1]]
    scmax 	<- which.min(abs(targetFeatTable$rtMax[i] - RTtime))[[1]]
    # mz, length and intensity are not used by centWave
    ROIList[[i]] <- list(mz=targetFeatTable$mz[i], mzmin=targetFeatTable$mzMin[i], mzmax=targetFeatTable$mzMax[i], scmin=scmin, scmax=scmax, length=-1, intensity=-1)
  }
  return(ROIList)
}


#' Integrate ROI and find target features
#'
#' Integrate features in the ROI using \code{CentWave} and keep in each ROI the feature with the highest integrated intensity.
#'
#' @param rawSpec an \code{\link[MSnbase]{OnDiskMSnExp-class}}
#' @param ROIList a list of ROIs as generated by \code{\link{makeROIList}}
#' @param ppm \code{\link[xcms]{findChromPeaks-centWave}} parameter: \emph{maxmial tolerated m/z deviation in consecutive scans, in ppm (parts per million)}
#' @param snthresh \code{\link[xcms]{findChromPeaks-centWave}} parameter: \emph{signal to noise ratio cutoff}
#' @param noise \code{\link[xcms]{findChromPeaks-centWave}} parameter: \emph{optional argument which is useful for data that was centroided without any intensity threshold, centroids with intensity < \code{noise} are omitted from ROI detection}
#' @param prefilter \code{\link[xcms]{findChromPeaks-centWave}} parameter: \emph{\code{prefilter=c(k,I)}. Prefilter step for the first phase. Mass traces are only retained if they contain at least \code{k} peaks with intensity >= \code{I}.}
#' @param peakwidth \code{\link[xcms]{findChromPeaks-centWave}} parameter: \emph{Chromatographic peak width, given as range (min,max) in seconds}
#' @param verbose (bool) if TRUE message the time taken and number of features found (total and matched to targets)
#' @param fitGauss (bool) if TRUE fits peak with option \code{CentWaveParam(..., fitgauss=TRUE)}.
#'
#' @return A \code{data.frame} with targeted features as rows and peak measures as columns (see Details).
#'
#' \subsection{Details:}{
#'   The returned \code{data.frame} is structured as follow (from \code{\link[xcms]{findChromPeaks-centWave}}):
#'   \tabular{ll}{
#'     mz \tab weighted (by intensity) mean of peak m/z across scans\cr
#'     mzmin \tab m/z peak minimum\cr
#'     mzmax \tab m/z peak maximum\cr
#'     rt \tab retention time of peak midpoint\cr
#'     rtmin \tab leading edge of peak retention time\cr
#'     rtmax \tab trailing edge of peak retention time\cr
#'     into \tab integrated peak intensity\cr
#'     intb \tab baseline corrected integrated peak intensity\cr
#'     maxo \tab maximum peak intensity\cr
#'     sn \tab Signal/Noise ratio, defined as \code{(maxo - baseline)/sd}, where \code{maxo} is the maximum peak intensity, \code{baseline} the estimated baseline value and \code{sd} the standard deviation of local chromatographic noise.\cr
#'     egauss \tab RMSE of Gaussian fit\cr
#'     mu \tab Gaussian parameter mu\cr
#'     sigma \tab Gaussian parameter sigma\cr
#'     h \tab Gaussian parameter h\cr
#'     f \tab Region number of m/z ROI where the peak was localised\cr
#'     dppm \tab m/z deviation of mass trace across scans in ppm\cr
#'     scale \tab Scale on which the peak was localised\cr
#'     scpos \tab Peak position found by wavelet analysis (scan number)\cr
#'     scmin \tab Left peak limit found by wavelet analysis (scan number)\cr
#'     scmax \tab Right peak limit found by wavelet analysis (scan number)\cr
#'   }
#' }
#'
#' @examples
#' \dontrun{
#' ## Load data
#' library(faahKO)
#' library(MSnbase)
#' netcdfFilePath <- system.file('cdf/KO/ko15.CDF', package = "faahKO")
#' raw_data       <- MSnbase::readMSData(netcdfFilePath, centroided=TRUE, mode='onDisk')
#'
#' ## targetFeatTable
#' targetFeatTable     <- data.frame(matrix(vector(), 2, 8, dimnames=list(c(), c("cpdID",
#'                          "cpdName", "rtMin", "rt", "rtMax", "mzMin", "mz", "mzMax"))),
#'                          stringsAsFactors=F)
#' targetFeatTable[1,] <- c(1, "Cpd 1", 3310., 3344.888, 3390., 522.194778, 522.2, 522.205222)
#' targetFeatTable[2,] <- c(2, "Cpd 2", 3280., 3385.577, 3440., 496.195038, 496.2, 496.204962)
#' targetFeatTable[,c(1,3:8)] <- sapply(targetFeatTable[,c(1,3:8)], as.numeric)
#'
#' ROIList        <- makeROIList(raw_data, targetFeatTable)
#'
#' foundPeakTable <- findTargetFeatures(raw_data, ROIList)
#' foundPeakTable
#' #   found    mz mzmin mzmax       rt    rtmin    rtmax     into     intb    maxo     sn
#' # 1  TRUE 522.2 522.2 522.2 3344.888 3322.979 3379.317 25792525 25768308  889280   1840
#' # 2  TRUE 496.2 496.2 496.2 3382.447 3362.102 3409.051 32873727 32818664 1128960   1471
#' # egauss mu sigma  h f dppm scale scpos scmin scmax lmin lmax sample is_filled
#' #     NA NA    NA NA 1    0     5   540   535   545   24   60      1         0
#' #     NA NA    NA NA 2    0     5   564   559   569   68   98      1         0
#' }
findTargetFeatures <- function(rawSpec, ROIList, ppm=20, snthresh=3, noise=400, prefilter=c(7,400), peakwidth=c(2,20), verbose=FALSE, fitGauss=FALSE){
  stime <- Sys.time()

  ## Set centwave parameters and find peaks
  CWParam         <- xcms::CentWaveParam(roiList = ROIList, ppm = ppm, snthresh = snthresh, noise = noise, prefilter = prefilter, peakwidth = peakwidth, integrate = 1, verboseColumns = TRUE, fitgauss = fitGauss)
  resPeakSearch   <- xcms::findChromPeaks(rawSpec, param = CWParam)
  foundPeakTable  <- data.frame(xcms::chromPeaks(resPeakSearch))

  # Keep only the highest feature per ROI
  filteredFoundPeak <- data.frame(matrix(vector(), length(ROIList), (dim(foundPeakTable)[2]+1), dimnames=list(c(), c("found",colnames(foundPeakTable)))), stringsAsFactors=F)
  for (i in 1:dim(filteredFoundPeak)[1]) {
    if (i %in% foundPeakTable$f){
      # a peak has been found
      filteredFoundPeak[i,1]  <- TRUE
      filteredFoundPeak[i,-1] <- foundPeakTable[ foundPeakTable$f==i, ][ which.max( foundPeakTable[foundPeakTable$f==i,]$into), ]
    } else {
      # no peak found
      filteredFoundPeak[i,1] <- FALSE
    }
  }
  etime <- Sys.time()
  if (verbose) {
    message('Found ', sum(filteredFoundPeak$found), '/',length(ROIList), ' features (', dim(foundPeakTable)[1], ' total) in ', round(as.double(difftime(etime,stime)),2),' ',units( difftime(etime,stime)))
  }

  return(filteredFoundPeak)
}


#' Calculate chromatographic peak properties
#'
#' Calculate the ppm error, retention time deviation, FWHM, number of scans, tailing factor and asymmetry factor for each measured feature.
#'
#' @param rawSpec an \code{\link[MSnbase]{OnDiskMSnExp-class}}
#' @param targetFeatTable a \code{\link{data.frame}} of compounds to target as rows. Columns: \code{cpdID} (int), \code{cpdName} (str), \code{rtMin} (float in seconds), \code{rt} (float in seconds, or \emph{NA}), \code{rtMax} (float in seconds), \code{mzMin} (float), \code{mz} (float or \emph{NA}), \code{mzMax} (float).
#' @param foundPeakTable a \code{data.frame} as generated by \code{\link{findTargetFeatures}}, with features as rows and peak properties as columns. The following columns are mandatory: \code{mz}, \code{rt}, \code{scmin}, \code{scpos}, \code{scmax}, \code{sigma}.
#' @param usePreviousEICs (list of S4 \code{\link[MSnbase]{Chromatogram-class}} or NULL) If not NULL, use the inputed list of EICs (corresponding to each ROI) for statistics. If NULL, the EICs will be extracted from \code{rawSpec} during the function. Only use this option to reduce the number of file reads (EICs are obtained using \code{EICs <- xcms::chromatogram(rawSpec, rt = data.frame(rt_lower=targetFeatTable$rtMin, rt_upper=targetFeatTable$rtMax), mz = data.frame(mz_lower=targetFeatTable$mzMin, mz_upper=targetFeatTable$mzMax))}). If the EICs provided do not match the spectra, the statistics will be erronous.
#' @param verbose (bool) if TRUE message when NA scans are removed
#'
#' @return A \code{data.frame} with measured compounds as rows and measurements and properties as columns (see Details).
#'
#' \subsection{Details:}{
#'   The returned \code{data.frame} is structured as follow:
#'   \tabular{ll}{
#'     cpdID \tab database compound ID (if in input)\cr
#'     cpdName \tab compound name (if in input)\cr
#'     found \tab (bool) TRUE if compound was found in the raw data\cr
#'     mz \tab weighted (by intensity) mean of peak m/z across scans\cr
#'     mzmin \tab m/z peak minimum\cr
#'     mzmax \tab m/z peak maximum\cr
#'     rt \tab retention time of peak midpoint\cr
#'     rtmin \tab leading edge of peak retention time\cr
#'     rtmax \tab trailing edge of peak retention time\cr
#'     into \tab integrated peak intensity\cr
#'     intb \tab baseline corrected integrated peak intensity\cr
#'     maxo \tab maximum peak intensity\cr
#'     sn \tab Signal/Noise ratio, defined as \code{(maxo - baseline)/sd}, where \code{maxo} is the maximum peak intensity, \code{baseline} the estimated baseline value and \code{sd} the standard deviation of local chromatographic noise.\cr
#'     egauss \tab RMSE of Gaussian fit\cr
#'     mu \tab Gaussian parameter mu\cr
#'     sigma \tab Gaussian parameter sigma\cr
#'     h \tab Gaussian parameter h\cr
#'     f \tab Region number of m/z ROI where the peak was localised\cr
#'     dppm \tab m/z deviation of mass trace across scans in ppm\cr
#'     scale \tab Scale on which the peak was localised\cr
#'     scpos \tab Peak position found by wavelet analysis (scan number)\cr
#'     scmin \tab Left peak limit found by wavelet analysis (scan number)\cr
#'     scmax \tab Right peak limit found by wavelet analysis (scan number)\cr
#'     ppm_error \tab difference in ppm between the expected and measured m/z\cr
#'     rt_dev_sec \tab difference in seconds between the expected and measured rt\cr
#'     FWHM \tab full width at half maximum (in seconds), not available if \code{fitGauss=FALSE}\cr
#'     FWHM_ndatapoints \tab number of scans on the peak\cr
#'     tailingFactor \tab the tailing factor is a measure of peak tailing.It is defined as the distance from the front slope of the peak to the back slope divided by twice the distance from the center line of the peak to the front slope, with all measurements made at 5\% of the maximum peak height. The tailing factor of a peak will typically be similar to the asymmetry factor for the same peak, but the two values cannot be directly converted\cr
#'     asymmetryFactor \tab the asymmetry factor is a measure of peak tailing. It is defined as the distance from the center line of the peak to the back slope divided by the distance from the center line of the peak to the front slope, with all measurements made at 10\% of the maximum peak height. The asymmetry factor of a peak will typically be similar to the tailing factor for the same peak, but the two values cannot be directly converted\cr
#'   }
#' }
#'
#' @references Adapted for XCMS3 from Jan Stanstrup https://cdn.rawgit.com/stanstrup/QC4Metabolomics/master/MetabolomiQCsR/inst/doc/standard_stats.html#calculating-statistics
#'
#' @examples
#' \dontrun{
#' ## Load data
#' library(faahKO)
#' library(MSnbase)
#' netcdfFilePath <- system.file('cdf/KO/ko15.CDF', package = "faahKO")
#' raw_data       <- MSnbase::readMSData(netcdfFilePath, centroided=TRUE, mode='onDisk')
#'
#' ## targetFeatTable
#' targetFeatTable     <- data.frame(matrix(vector(), 2, 8, dimnames=list(c(), c("cpdID",
#'                          "cpdName", "rtMin", "rt", "rtMax", "mzMin", "mz", "mzMax"))),
#'                          stringsAsFactors=F)
#' targetFeatTable[1,] <- c(1, "Cpd 1", 3310., 3344.888, 3390., 522.194778, 522.2, 522.205222)
#' targetFeatTable[2,] <- c(2, "Cpd 2", 3280., 3385.577, 3440., 496.195038, 496.2, 496.204962)
#' targetFeatTable[,c(1,3:8)] <- sapply(targetFeatTable[,c(1,3:8)], as.numeric)
#'
#' ROIList        <- makeROIList(raw_data, targetFeatTable)
#'
#' foundPeakTable <- findTargetFeatures(raw_data, ROIList)
#'
#' peakStatistics <- getTargetFeatureStatistic(raw_data, targetFeatTable, foundPeakTable)
#' peakStatistics
#' #    found    mz mzmin mzmax       rt    rtmin    rtmax     into     intb   maxo    sn egauss mu
#' # 1   TRUE 522.2 522.2 522.2 3344.888 3322.979 3379.317 25792525 25768308 889280  1840     NA NA
#' # 2   TRUE 496.2 496.2 496.2 3382.447 3362.102 3409.051 32873727 32818664 1128960 1471     NA NA
#' #    sigma h  f dppm scale scpos scmin scmax lmin lmax sample is_filled   ppm_error rt_dev_sec
#' # 1     NA NA 1    0     5   540   535   545   24   60      1         0  0.02336270       0.00
#' # 2     NA NA 2    0     5   564   559   569   68   98      1         0  0.02458686       3.13
#' #    FWHM FWHM_ndatapoints tailingFactor asymmetryFactor
#' # 1    NA               11            NA        1.484000
#' # 2    NA               11            NA        2.708291
#' }
getTargetFeatureStatistic <- function(rawSpec, targetFeatTable, foundPeakTable, usePreviousEICs=NULL, verbose=FALSE) {

  ## Define the peak_shape_stat() -----------------------
  #
  # Calculate tailing factor and asymmetry factor
  #
  # Tailing Factor and Asymmetry Factor following the equations from http://www.chromforum.org/viewtopic.php?t=20079
  #
  # @param featEIC A single EIC as generated by \code{\link[xcms]{chromatogram}}
  # @param apexRT (float) retention time in seconds of the measured peak apex
  # @param statistic (str) either \code{tailingFactor} or \code{asymmetryFactor}
  # @param verbose (bool) if TRUE message when NA scans are removed
  #
  # @return Tailing factor or Asymmetry factor value
  #
  # @references Adapted for XCMS3 from QC4Metabolomics by Jan Stanstrup https://github.com/stanstrup/QC4Metabolomics/blob/master/MetabolomiQCsR/R/standard_stats.R
  # @references Equations from http://www.chromforum.org/viewtopic.php?t=20079
  #
  peak_shape_stat <- function(featEIC, apexRT, statistic="tailingFactor", verbose=FALSE){

    # A B and C are retention time in seconds. C is RT of the apex, A is left side as x%, B is right side at x%. x% (cutoff) depends of the statistic employed.

    #check inputs
    if(is.na(apexRT)) return(NA)

    # Remove scans with intensity NA from the feature
    if (sum(is.na(xcms::intensity(featEIC))) != 0) {
      if(verbose){
        message(sum(is.na(xcms::intensity(featEIC))), '/', length(xcms::intensity(featEIC)), ' scans removed due to NA')
      }
      filterNA    <- !is.na(xcms::intensity(featEIC))
      featEIC_RT  <- xcms::rtime(featEIC)[filterNA]
      featEIC_Int <- xcms::intensity(featEIC)[filterNA]
    } else {
      featEIC_RT  <- xcms::rtime(featEIC)
      featEIC_Int <- xcms::intensity(featEIC)
    }

    # get the scan number of the RT apex
    apexRT_scan_number <- which.min(abs(featEIC_RT - apexRT))
    # the RT matching this apex (also known as C)
    C   <- featEIC_RT[apexRT_scan_number]

    # ensure we don't overshoot the index
    # -2 / +2
    if( (apexRT_scan_number-2)>=1 ){ startRange2pt <- apexRT_scan_number-2 }
    else { startRange2pt <- 1}
    if( (apexRT_scan_number+2)<=length(featEIC_RT) ){ endRange2pt <- apexRT_scan_number+2 }
    else { endRange2pt <- length(featEIC_RT) }
    # -1 / +1
    if( (apexRT_scan_number-1)>=1 ){ startRange1pt <- apexRT_scan_number-1 }
    else { startRange1pt <- 1}
    if( (apexRT_scan_number+1)<=length(featEIC_RT) ){ endRange1pt <- apexRT_scan_number+1 }
    else { endRange1pt <- length(featEIC_RT) }

    # maximum intensity across the 5 central scans to avoid problems if the center is not the highest
    max_int <- max(featEIC_Int[startRange2pt:endRange2pt], na.rm = TRUE)

    # check values are non-0 for 3 central scans, otherwise exit
    if( all( featEIC_Int[(startRange1pt):(endRange1pt)] == 0) ) return(NA)


    # Median smoothing. Avoids single zero values breaking things. Already smooth peaks are unaffected.
    if(  !all( c(featEIC_Int[startRange1pt], featEIC_Int[endRange1pt]) == 0 )  ){ # If the values on each side of the mid of the peak are both 0 don't do smoothing (a 1 scan spike would cause this).
      featEIC_Int  <- stats::smooth(featEIC_Int, kind="3")
    }


    # If middle scan is zero after smoothing, exit
    if( featEIC_Int[apexRT_scan_number] == 0 ) return(NA)


    # Left side of the peak
    # Get each scan RT, reverse order, normalise by max_intensity (so just need to look for x% (cutoff) no need to divide later)
    A_side_rt       <- rev(featEIC_RT[1:apexRT_scan_number]) # can use featEIC as RT didn't change
    # Get scan, reverse order, normalise by max_intensity (so just need to look for x% (cutoff) no need to divide later)
    A_side_normInt  <- rev(featEIC_Int[1:apexRT_scan_number])/max_int

    # Right side of the peak
    # Get each scan RT
    B_side_rt       <- featEIC_RT[apexRT_scan_number:length(MSnbase::rtime(featEIC))] # can use featEIC as RT didn't change
    # Get scan, normalise by max_intensity
    B_side_normInt  <- featEIC_Int[apexRT_scan_number:length(featEIC_Int)]/max_int


    # Change the cut-off depending on the statistic
    cutoff <- switch(statistic, tailingFactor=0.05, asymmetryFactor=0.1)

    ## Get A (left side)
    # Keep points all points > cutoff and 1 point < cutoff, then interpolate cutoff retention time
    A_cutoff_pt     <- match(-1,sign(A_side_normInt - cutoff)) # positions of scans up to when it's too far (if negative, we are past the cutoff)
    if (!is.na(A_cutoff_pt)) {
      A_scans_toKeep  <- seq(1, A_cutoff_pt)
      A_side_rt       <- A_side_rt[A_scans_toKeep]
      A_side_normInt  <- A_side_normInt[A_scans_toKeep]
      # Check there was a point over cutoff (only 1 point, can't work)
      if( length(A_scans_toKeep)==1 ) return(NA)
    } else {
      return(NA)
    }

    # Approximate the RT at the cutoff intensity
    A <- stats::approx(x=A_side_normInt, y=A_side_rt, xout=cutoff)$y


    # Get B (right side)
    # Keep points all points > cutoff and 1 point < cutoff, then interpolate cutoff retention time
    B_cutoff_pt     <- match(-1,sign(B_side_normInt - cutoff)) # positions of scans up to when it's too far (if negative, we are past the cutoff)
    if (!is.na(B_cutoff_pt)) {
      B_scans_toKeep  <- seq(1, B_cutoff_pt)
      B_side_rt       <- B_side_rt[B_scans_toKeep]
      B_side_normInt  <- B_side_normInt[B_scans_toKeep]
      # Check there was a point over cutoff (only 1 point, can't work)
      if( length(B_scans_toKeep)==1 ) return(NA)
    } else {
      return(NA)
    }

    # Approximate the RT at the cutoff intensity
    B <- stats::approx(x=B_side_normInt, y=B_side_rt, xout=cutoff)$y

    # remove the name from the named float
    if(statistic=="tailingFactor") {
      result <- (B-A)/(2*(C-A))
      return( result[[1]] )
    }
    if(statistic=="asymmetryFactor") {
      result <- (B-C)/(C-A)
      return( result[[1]] )
    }
  }
  ## ----------------------------------------------------

	stime <- Sys.time()

  if (dim(targetFeatTable)[1] != dim(foundPeakTable)[1]) {
    stop("Number of features in targetFeatTable (", dim(targetFeatTable)[1],") and foundPeakTable (", dim(foundPeakTable)[1], ") do not match!")
  }

	if (all(!is.null(usePreviousEICs))) {
		if (!is.list(usePreviousEICs)) {
			stop("usePreviousEICs is not a list of xcms::Chromatogram")
		}
		if (length(usePreviousEICs) != dim(targetFeatTable)[1]) {
			stop("Number of chromatograms in usePreviousEICs (", length(usePreviousEICs),") and features in targetFeatTable (", dim(targetFeatTable)[1], ") do not match!")
		}
		if (!methods::is(usePreviousEICs[[1]], 'Chromatogram')) {
			stop("usePreviousEICs is not a list of xcms::Chromatogram")
		}
	}

	## Extract all EICs from raw data (found features) if none passed as input
	if (all(!is.null(usePreviousEICs))) {
		if (verbose) { message("Previously loaded EICs used for peak statistics") }
		EICs 	<- usePreviousEICs
	} else {
		EICs	<- xcms::chromatogram(rawSpec, rt = data.frame(rt_lower=targetFeatTable$rtMin, rt_upper=targetFeatTable$rtMax), mz = data.frame(mz_lower=targetFeatTable$mzMin, mz_upper=targetFeatTable$mzMax))
	}

  ## Calculate the statistics
  peakStat	<- data.frame(matrix(vector(), dim(targetFeatTable)[1], 6, dimnames=list(c(), c("ppm_error", "rt_dev_sec", "FWHM", "FWHM_ndatapoints", "tailingFactor", "asymmetryFactor"))), stringsAsFactors=F)

  for (i in 1:dim(targetFeatTable)[1]) {
    # If the feature wasn't found we cannot work with it
    if (foundPeakTable$found[i]) {
      # ppm_error
      if (!is.na(targetFeatTable$mz[i])) {
        peakStat$ppm_error[i] <- (abs(foundPeakTable$mz[i] - targetFeatTable$mz[i])/targetFeatTable$mz[i])*1E6
      }
      # rt_dev_sec
      if (!is.na(targetFeatTable$rt[i])) {
        peakStat$rt_dev_sec[i] <- abs(foundPeakTable$rt[i] - targetFeatTable$rt[i])
      }

      # FWHM
      # need a function to approximate retention time between the existing scans
      if ((foundPeakTable$scpos[i]!=-1) & (foundPeakTable$scmin[i]!=-1) & (foundPeakTable$scmax[i]!=-1)) {
        approx_rt_from_scan <- stats::approxfun( seq_along( xcms::rtime(rawSpec)), xcms::rtime(rawSpec) ) # approximation of RT at any scan (even not integer)
        FWHM_scan           <- 2*sqrt(2*log(2))*foundPeakTable$sigma[i]
        FWHM_start          <- approx_rt_from_scan(foundPeakTable$scpos[i] - FWHM_scan/2) # min rt at half height (calculate the min scan at half height, convert to a RT with approx function)
        FWHM_end            <- approx_rt_from_scan(foundPeakTable$scpos[i] + FWHM_scan/2)
        peakStat$FWHM[i]             <- FWHM_end - FWHM_start
        peakStat$FWHM_ndatapoints[i] <- (foundPeakTable$scmax[i] - foundPeakTable$scmin[i]) + 1 # number of datapoints for peak measurement
      }
      # Tailing Factor
      peakStat$tailingFactor[i]      <- peak_shape_stat(EICs[[i]], foundPeakTable$rt[i], statistic = "tailingFactor")
      # Asymmetry Factor
      peakStat$asymmetryFactor[i]   <- peak_shape_stat(EICs[[i]], foundPeakTable$rt[i], statistic = "asymmetryFactor")
    }
  }

  ## group the results and return
  finalTable  <- cbind.data.frame(foundPeakTable, peakStat)

	etime <- Sys.time()
	if (verbose) {
    message('Peak statistics done in: ', round(as.double(difftime(etime,stime)),2),' ',units( difftime(etime,stime)))
  }

  return( finalTable )
}


#' Plot a raw data and detected feature in a ROI
#'
#' plot a ROI (x is RT, y is intensity) with the matching detected peak rt and peakwidth under it
#'
#' @param EIC xcms::chromatograms (single spectra)
#' @param cpdID (str) Compound ID
#' @param cpdName (str) Compound Name
#' @param rt (float) detected peak apex retention time (in sec)
#' @param rtmin (float) detected peak minimum retention time (in sec)
#' @param rtmax (float) detected peak maximum retention time (in sec)
#' @param mzmin (float) ROI minimum m/z (matching EIC)
#' @param mzmax (float) ROI maximum m/z (matching EIC)
#'
#' @return Grob (ggplot object)
plotEICDetectedPeakwidth  <- function(EIC, cpdID, cpdName, rt, rtmin, rtmax, mzmin, mzmax) {

  ## Raw spectra
  # prepare data
  Int         <- xcms::intensity(EIC)
  filterNA    <- !is.na(Int)
  Int         <- Int[filterNA]
  RT          <- xcms::rtime(EIC)[filterNA]
  title       <- paste('CpdID: ', cpdID, ' - ', cpdName, ' ', round(mzmin, 4), '-', round(mzmax, 4))
  # plot
  p_spec1     <- ggplot2::ggplot(NULL, ggplot2::aes(x), environment = environment()) + ggplot2::ggtitle(title) + ggplot2::theme_bw() + ggplot2::ylab('Intensity') + ggplot2::theme(axis.title.x=ggplot2::element_blank(), axis.text.x=ggplot2::element_blank(), plot.title=ggplot2::element_text(size=ggplot2::rel(1)))
  p_spec1     <- p_spec1 + ggplot2::geom_line(data=data.frame(x=RT, y=Int), ggplot2::aes_string(x="x", y="y"))

  ## peakwidth plot
  p_peakwidth <- ggplot2::ggplot(NULL, ggplot2::aes(x), environment = environment()) + ggplot2::theme_bw() + ggplot2::xlab('Retention Time (sec)') + ggplot2::theme(axis.title.y=ggplot2::element_blank(), axis.text.y=ggplot2::element_blank(), axis.ticks.y=ggplot2::element_blank()) + ggplot2::scale_y_continuous(breaks=NULL)
  p_peakwidth <- p_peakwidth + ggplot2::geom_point(data=data.frame(x=rt, y=0), ggplot2::aes(x=x, y=y), colour='red', size=3)
  p_peakwidth <- p_peakwidth + ggplot2::geom_line(data=data.frame(x=c(rtmin,rtmax), y=c(0,0)), ggplot2::aes(x=x, y=y, group=y), colour='red', size=1)

  # set common x lim
  minX        <- min(ggplot2::layer_scales(p_spec1)$x$range$range[1], ggplot2::layer_scales(p_peakwidth)$x$range$range[1])
  maxX        <- max(ggplot2::layer_scales(p_spec1)$x$range$range[2], ggplot2::layer_scales(p_peakwidth)$x$range$range[2])
  p_spec1     <- p_spec1 + ggplot2::xlim(minX, maxX)
  p_peakwidth <- p_peakwidth + ggplot2::xlim(minX, maxX)
  # convert to gtables
  p_spec1     <- ggplot2::ggplot_gtable(ggplot2::ggplot_build(p_spec1))
  p_peakwidth <- ggplot2::ggplot_gtable(ggplot2::ggplot_build(p_peakwidth))
  #  find the widths of each of the plots, calculate the maximum and then apply it to each of them individually. This effectively applies a uniform layout to each of the plots.
  maxWidth                <- grid::unit.pmax(p_spec1$widths[2:3], p_peakwidth$widths[2:3])
  p_spec1$widths[2:3]     <- maxWidth
  p_peakwidth$widths[2:3] <- maxWidth
  p     <- gridExtra::grid.arrange(p_spec1, p_peakwidth, heights=c(6,1))

  return(p)
}


#' Save to disk a plot of all ROI EIC and detected feature range
#'
#' Plot and save a \code{.png} of all ROI (x is RT, y is intensity), with the matching detected peak rt and peakwidth under it.
#'
#' @param EICs (list) list of xcms::chromatograms (one per ROI, same order as rows in foundPeakTable)
#' @param foundPeakTable (data.frame) \code{data.frame} as generated by \code{\link{findTargetFeatures}}, with features as rows and peak properties as columns. The following columns are mandatory: \code{cpdID}, \code{cpdName}, \code{rt}, \code{rtmin}, \code{rtmax}, \code{mzmin}, \code{mzmax}.
#' @param savePath (str) Full path to save a \emph{.png} of all ROI EICs , expect \code{'filepath/filename.png'}.
#' @param width (float) Width in cm for a single ROI plot (if more than one plot in total, 2 columns will be used). dpi set to a 100.
#' @param height (float) height in a cm for a single ROI plot. dpi set to 100
#' @param verbose (bool) if TRUE message progress
#'
#' @return None
saveMultiEIC   <- function(EICs, foundPeakTable, savePath, width=15, height=15, verbose=TRUE) {

  ## check input
  if (length(EICs) != dim(foundPeakTable)[1]) {
    stop("Number of chromatograms in EICs (", length(EICs),") and features in foundPeakTable (", dim(foundPeakTable)[1], ") do not match!")
  }

  ## Generate each ROI plot
  p_all         <- vector("list", length(EICs))
  for (i in 1:length(EICs)) {
    p_all[[i]]  <- plotEICDetectedPeakwidth(EICs[[i]], foundPeakTable$cpdID[i], foundPeakTable$cpdName[i], foundPeakTable$rt[i], foundPeakTable$rtmin[i], foundPeakTable$rtmax[i], foundPeakTable$mzmin[i], foundPeakTable$mzmax[i])
  }

  ## Set save parameters
  targetFolder  <- dirname(savePath)
  targetFile    <- basename(savePath)
  nSubplot      <- length(p_all)

  if (nSubplot==1) {
    ncol    <- 1
  } else {
    ncol    <- 2
    nrow    <- ceiling(nSubplot/2)
    width   <- width * ncol
    height  <- height * nrow
  }

  ## Save
  ggplot2::ggsave(file=targetFile, plot=gridExtra::arrangeGrob(grobs=p_all, ncol=ncol), device='png', path=targetFolder, dpi=100, width=width, height=height, units='cm', limitsize=FALSE)

  if (verbose) { message('Summary EIC plot saved at: ', savePath)}
}


#' Parse acquisition date from a mzML file
#'
#' Extract acquisition date (`'startTimeStamp'``) from a mzML file. In case of failure (or the file is not a \code{mzML}) returns NULL
#'
#' @param mzMLPath (str) path to mzML raw data file
#' @param verbose (bool) if TRUE message progress
#'
#' @return POSIXct or NA
getAcquisitionDatemzML  <- function(mzMLPath, verbose=TRUE) {

  ## Check input
  mzMLPath  <- normalizePath(mzMLPath, mustWork=FALSE)
  # not a mzML extension
  if (tolower(stringr::str_sub(basename(mzMLPath), start=-5)) != '.mzml') {
    if (verbose) { message('Check input, mzMLPath must be a .mzML') }
    return(NA)
  }

  stime <- Sys.time()

  ## Parse XML
  acqTime <- tryCatch(
    {
      ## try
      xmlfile   <- XML::xmlParse(mzMLPath)
      xmltop    <- XML::xmlRoot(xmlfile)
      # check top level structure
      if (XML::xmlName(xmltop) != "indexedmzML") {
        if (verbose) { message('Check input, mzMLPath is not a valid mzML file') }
        return(NA)
      } else {
        acqTime   <- strptime(XML::xmlGetAttr(xmltop[['mzML']][['run']], "startTimeStamp"), format = '%Y-%m-%dT%H:%M:%S')
      }
    },
    error=function(cond) {
      ## catch
      if (verbose) { message('Check input, failure while parsing mzMLPath') }
      return(NA)
    }
  )

  ## Output
  etime <- Sys.time()
  if (verbose) { message('Acquisition date parsed in: ', round(as.double(difftime(etime,stime)),2),' ',units( difftime(etime,stime))) }

  return(acqTime)
}


#' Integrate fallback integration regions
#'
#' Integrate region defined in FIR if a feature is not found
#'
#' @param rawSpec an \code{\link[MSnbase]{OnDiskMSnExp-class}}
#' @param FIR (data.frame) Fallback Integration Regions (FIR) to integrate when a feature is not found. Compounds as row are identical to the targeted features, columns are \code{rtMin} (float in seconds), \code{rtMax} (float in seconds), \code{mzMin} (float), \code{mzMax} (float)
#' @param foundPeakTable a \code{data.frame} as generated by \code{\link{findTargetFeatures}}, with features as rows and peak properties as columns. The following columns are mandatory: \code{found}, \code{is_filled}, \code{mz}, \code{mzmin}, \code{mzmax}, \code{rt}, \code{rtmin}, \code{rtmax}, \code{into}, \code{intb}, \code{maxo}.
#' @param verbose (bool) if TRUE message progress
#'
#' @return an updated foundPeakTable with FIR integration values
integrateFIR <- function(rawSpec, FIR, foundPeakTable, verbose=TRUE) {

  ## Check input
  if (dim(FIR)[1] != dim(foundPeakTable)[1]) {
    stop('Check input, FIR must have the same number of rows as foundPeakTable')
  }

  ## init
  stime             <- Sys.time()
  needsFilling      <- !(foundPeakTable$found)
  needsFilling_idx  <- seq(dim(foundPeakTable)[1])[needsFilling]
  outTable          <- foundPeakTable

  ## only run where replacement is needed
  if (sum(needsFilling) != 0) {

    if (verbose) { message(sum(needsFilling), " features to integrate with FIR") }

    # store results
    tmpResult   <- data.frame(matrix(vector(), sum(needsFilling), 9, dimnames=list(c(), c("mzMin", "mz", "mzMax", "rtMin", "rt", "rtMax", "maxo", "into", "intb"))))

    ## iterate over features to integrate
    for (i in needsFilling_idx) {

      # get all data points
      peakData  <- xcms::extractMsData(rawSpec, mz = c(FIR$mzMin[i], FIR$mzMax[i]), rt = c(FIR$rtMin[i], FIR$rtMax[i]))[[1]]

      # Only continue if a scan is found in the box
      if (dim(peakData)[1] != 0) {

        # scanDist is the mean distance in sec between scans (used for integral)
        rtRange   <- unique(peakData$rt)
        scanDist  <- diff(c(min(rtRange), max(rtRange))) / length(rtRange)

        # mzMin, mzMax, rtMin, rtMax (values taken from input)
        tmpResult[i, c("mzMin", "mzMax", "rtMin", "rtMax")]   <- FIR[i, c("mzMin", "mzMax", "rtMin", "rtMax")]

        # rt (rt of max intensity)
        tmpResult[i, "rt"]    <- peakData$rt[which.max(peakData$i)]

        # mz (weighted average of total intensity across all rt for each mz)
        # total intensity across rt for each mz
        mzRange               <- unique(peakData$mz)
        mzTotalIntensity      <- sapply(mzRange, function(x) {sum(peakData$i[peakData$mz == x])})
        # mz (is weighted average)
        tmpResult[i, "mz"]    <- stats::weighted.mean(mzRange, mzTotalIntensity)

        # maxo (max intensity)
        tmpResult[i, "maxo"]  <- max(peakData$i)

        # into
        # max intensity across mz for each rt
        rtMaxIntensity        <- sapply(rtRange, function(x) {max(peakData$i[peakData$rt == x])})
        # into is the max intensities summed over (discrete) rt, multiplied by the mean distance in sec between scans
        tmpResult[i, "into"]  <- sum(rtMaxIntensity) * scanDist
        # intb set the same as into
        tmpResult[i, "intb"]  <- tmpResult[i, "into"]


      ## If no scan found in that region, return default values
      } else {

        if (verbose) { message("No scan present in the FIR # ", i, ": rt and mz are set as the middle of the FIR box; maxo, into and intb are set to 0") }

        tmpResult[i, c("mzMin", "mzMax", "rtMin", "rtMax")]   <- FIR[i, c("mzMin", "mzMax", "rtMin", "rtMax")]
        tmpResult[i, "rt"]    <- mean(c(FIR$rtMin[i], FIR$rtMax[i]))
        tmpResult[i, "mz"]    <- mean(c(FIR$mzMin[i], FIR$mzMax[i]))
        tmpResult[i, "maxo"]  <- 0
        tmpResult[i, "into"]  <- 0
        tmpResult[i, "intb"]  <- 0
      }
    }

    # Replace results with FIR integration
    outTable[needsFilling_idx, c("mzmin", "mz", "mzmax", "rtmin", "rt", "rtmax", "maxo", "into", "intb")] <- tmpResult[needsFilling_idx, c("mzMin", "mz", "mzMax", "rtMin", "rt", "rtMax", "maxo", "into", "intb")]
    outTable$is_filled[needsFilling_idx]  <- TRUE
    outTable$found[needsFilling_idx]      <- TRUE
  }

  ## Output
  etime <- Sys.time()
  if (verbose) { message('FIR integrated in: ', round(as.double(difftime(etime,stime)),2),' ',units( difftime(etime,stime))) }

  return(outTable)
}

